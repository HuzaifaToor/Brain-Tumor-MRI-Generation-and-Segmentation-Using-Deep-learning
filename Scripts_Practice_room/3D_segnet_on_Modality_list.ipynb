{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3D_segnet_on_Modality_list.ipynb","provenance":[],"mount_file_id":"15Hkl-ryyqoOhStBzmdL6fLbzdL1S0Gfw","authorship_tag":"ABX9TyMVegHg/Z8/HL2dg5j+IRVe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"h0kwPBYQr-Tq"},"source":["!pip install keras_applications\n","!pip install classification-models-3D\n","!pip install efficientnet-3D\n","!pip install segmentation-models-3D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xBf_NQJnrQkO"},"source":["from sklearn.model_selection import train_test_split\n","import numpy as np\n","imgarray=np.load('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/Origna_data_handling/t1/image_t1_list.npy')\n","maskarray=np.load('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/Origna_data_handling/masks3D/mask_list.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUR2_NX3rr-8"},"source":["imgarray = imgarray[:,:,:,0:16]\n","maskarray = maskarray[:,:,:,0:16]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sFjWTWZrvdn","executionInfo":{"status":"ok","timestamp":1631864407820,"user_tz":-120,"elapsed":543,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"1ba67aee-325b-4332-c465-5b7cb4fe995d"},"source":["x_train1,x_test,y_train1,y_test=train_test_split(imgarray, maskarray, test_size = 0.20, random_state = 101)\n","x_train1.shape, x_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((168, 128, 128, 16), (42, 128, 128, 16))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"MlrIIddwr39Y"},"source":["def iou(y_true, y_pred, smooth = 100):\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return jac\n","\n","def dice_coef(y_true, y_pred, smooth = 100):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def precision(y_true, y_pred):\n","    '''Calculates the precision, a metric for multi-label classification of\n","    how many selected items are relevant.\n","    '''\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","def recall(y_true, y_pred):\n","    '''Calculates the recall, a metric for multi-label classification of\n","    how many relevant items are selected.\n","    '''\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","def accuracy(y_true, y_pred):\n","    '''Calculates the mean accuracy rate across all predictions for binary\n","    classification problems.\n","    '''\n","    return K.mean(K.equal(y_true, K.round(y_pred)))\n","\n","def iou(y_true, y_pred, smooth = 100):\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return jac\n","\n","def dice_coef(y_true, y_pred, smooth = 100):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def precision(y_true, y_pred):\n","    '''Calculates the precision, a metric for multi-label classification of\n","    how many selected items are relevant.\n","    '''\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","def recall(y_true, y_pred):\n","    '''Calculates the recall, a metric for multi-label classification of\n","    how many relevant items are selected.\n","    '''\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","def accuracy(y_true, y_pred):\n","    '''Calculates the mean accuracy rate across all predictions for binary\n","    classification problems.\n","    '''\n","    return K.mean(K.equal(y_true, K.round(y_pred)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfyQStGswnSn"},"source":["!pip install split-folders\n","import splitfolders  # or import split_folders\n","\n","input_folder = '/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/Origna_data_handling/t2/'\n","output_folder = '/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/SplitData/'\n","# Split with a ratio.\n","# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n","splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.8, .2), group_prefix=None) # default values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I7Y05hRPzeDz"},"source":["import os\n","import numpy as np\n","\n","\n","def load_img(img_dir, img_list):\n","    images=[]\n","    for i, image_name in enumerate(img_list):    \n","        if (image_name.split('.')[1] == 'npy'):\n","            \n","            image = np.load(img_dir+image_name)\n","                      \n","            images.append(image)\n","    images = np.array(images)\n","    \n","    return(images)\n","\n","\n","\n","\n","def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n","\n","    L = len(img_list)\n","\n","    #keras needs the generator infinite, so we will use while true  \n","    while True:\n","\n","        batch_start = 0\n","        batch_end = batch_size\n","\n","        while batch_start < L:\n","            limit = min(batch_end, L)\n","                       \n","            X = load_img(img_dir, img_list[batch_start:limit])\n","            Y = load_img(mask_dir, mask_list[batch_start:limit])\n","\n","            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n","\n","            batch_start += batch_size   \n","            batch_end += batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzkyuZWkziub"},"source":["import os\n","import numpy as np\n","#from custom_datagen import imageLoader\n","#import tensorflow as tf\n","import keras\n","from matplotlib import pyplot as plt\n","import glob\n","import random\n","\n","train_img_dir = \"/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/SplitData/train/t2_np/\"\n","train_mask_dir = \"/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/SplitData/train/mask_np/\"\n","train_img_list=os.listdir(train_img_dir)\n","train_mask_list = os.listdir(train_mask_dir)\n","\n","\n","val_img_dir = \"/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/SplitData/val/t2_np/\"\n","val_mask_dir = \"/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/SplitData/val/mask_np/\"\n","val_img_list=os.listdir(val_img_dir)\n","val_mask_list = os.listdir(val_mask_dir)\n","\n","batch_size = 2\n","\n","train_img_datagen = imageLoader(train_img_dir, train_img_list, \n","                                train_mask_dir, train_mask_list, batch_size)\n","\n","val_img_datagen = imageLoader(val_img_dir, val_img_list, \n","                                val_mask_dir, val_mask_list, batch_size)\n","\n","#Verify generator.... In python 3 next() is renamed as __next__()\n","img, msk = train_img_datagen.__next__()\n","\n","'''img_num = random.randint(0,img.shape[0]-1)\n","test_img=img[img_num]\n","test_mask=msk[img_num]\n","test_mask=np.argmax(test_mask, axis=3)\n","\n","n_slice=random.randint(0, test_mask.shape[2])\n","plt.figure(figsize=(12, 8))\n","\n","plt.subplot(121)\n","plt.imshow(test_img[:,:,n_slice], cmap='gray')\n","plt.title('Image t2')\n","\n","plt.subplot(122)\n","plt.imshow(test_mask[:,:,n_slice])\n","plt.title('Mask')\n","plt.show()\n","\n","#print((test_mask))'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCfh-126sNcr"},"source":["from keras.models import Model\n","from keras.layers import Input\n","from keras.layers.core import Activation, Reshape\n","from keras.layers import BatchNormalization\n","import tensorflow as tf\n","from torch.nn import MaxUnpool3d\n","from keras.layers import Conv3D, MaxPooling3D, concatenate, UpSampling3D\n","from tensorflow.keras.optimizers import SGD\n","\n","\n","def segnet(\n","        input_shape,\n","        n_labels,\n","        kernel=3,\n","        pool_size=(2, 2, 2),\n","        output_mode=\"softmax\"):\n","    # encoder\n","    inputs = Input(shape=input_shape)\n","\n","    conv_1 = Conv3D(64, (kernel, kernel, kernel), padding=\"same\")(inputs)\n","    conv_1 = BatchNormalization()(conv_1)\n","    conv_1 = Activation(\"relu\")(conv_1)\n","    conv_2 = Conv3D(64, (kernel, kernel, kernel), padding=\"same\")(conv_1)\n","    conv_2 = BatchNormalization()(conv_2)\n","    conv_2 = Activation(\"relu\")(conv_2)\n","\n","    pool_1= MaxPooling3D(pool_size)(conv_2)\n","\n","    conv_3 = Conv3D(128, (kernel, kernel, kernel), padding=\"same\")(pool_1)\n","    conv_3 = BatchNormalization()(conv_3)\n","    conv_3 = Activation(\"relu\")(conv_3)\n","    conv_4 = Conv3D(128, (kernel, kernel, kernel), padding=\"same\")(conv_3)\n","    conv_4 = BatchNormalization()(conv_4)\n","    conv_4 = Activation(\"relu\")(conv_4)\n","\n","    pool_2 = MaxPooling3D(pool_size)(conv_4)\n","\n","    conv_5 = Conv3D(256, (kernel, kernel, kernel), padding=\"same\")(pool_2)\n","    conv_5 = BatchNormalization()(conv_5)\n","    conv_5 = Activation(\"relu\")(conv_5)\n","    conv_6 = Conv3D(256, (kernel, kernel, kernel), padding=\"same\")(conv_5)\n","    conv_6 = BatchNormalization()(conv_6)\n","    conv_6 = Activation(\"relu\")(conv_6)\n","    conv_7 = Conv3D(256, (kernel, kernel, kernel), padding=\"same\")(conv_6)\n","    conv_7 = BatchNormalization()(conv_7)\n","    conv_7 = Activation(\"relu\")(conv_7)\n","\n","    pool_3 = MaxPooling3D(pool_size)(conv_7)\n","\n","    conv_8 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(pool_3)\n","    conv_8 = BatchNormalization()(conv_8)\n","    conv_8 = Activation(\"relu\")(conv_8)\n","    conv_9 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(conv_8)\n","    conv_9 = BatchNormalization()(conv_9)\n","    conv_9 = Activation(\"relu\")(conv_9)\n","    conv_10 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(conv_9)\n","    conv_10 = BatchNormalization()(conv_10)\n","    conv_10 = Activation(\"relu\")(conv_10)\n","\n","    pool_4 = MaxPooling3D(pool_size)(conv_10)\n","\n","    conv_11 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(pool_4)\n","    conv_11 = BatchNormalization()(conv_11)\n","    conv_11 = Activation(\"relu\")(conv_11)\n","    conv_12 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(conv_11)\n","    conv_12 = BatchNormalization()(conv_12)\n","    conv_12 = Activation(\"relu\")(conv_12)\n","    conv_13 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(conv_12)\n","    conv_13 = BatchNormalization()(conv_13)\n","    conv_13 = Activation(\"relu\")(conv_13)\n","\n","    pool_5 = MaxPooling3D(pool_size)(conv_13)\n","    print(\"Build enceder done..\")\n","\n","    # decoder\n","\n","    unpool_1 = UpSampling3D(pool_size)(pool_5)\n","\n","    conv_14 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(unpool_1)\n","    conv_14 = BatchNormalization()(conv_14)\n","    conv_14 = Activation(\"relu\")(conv_14)\n","    conv_15 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(conv_14)\n","    conv_15 = BatchNormalization()(conv_15)\n","    conv_15 = Activation(\"relu\")(conv_15)\n","    conv_16 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(conv_15)\n","    conv_16 = BatchNormalization()(conv_16)\n","    conv_16 = Activation(\"relu\")(conv_16)\n","\n","    unpool_2 = UpSampling3D(pool_size)(conv_16)\n","\n","    conv_17 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(unpool_2)\n","    conv_17 = BatchNormalization()(conv_17)\n","    conv_17 = Activation(\"relu\")(conv_17)\n","    conv_18 = Conv3D(512, (kernel, kernel, kernel), padding=\"same\")(conv_17)\n","    conv_18 = BatchNormalization()(conv_18)\n","    conv_18 = Activation(\"relu\")(conv_18)\n","    conv_19 = Conv3D(256, (kernel, kernel, kernel), padding=\"same\")(conv_18)\n","    conv_19 = BatchNormalization()(conv_19)\n","    conv_19 = Activation(\"relu\")(conv_19)\n","\n","    unpool_3 = UpSampling3D(pool_size)(conv_19)\n","\n","    conv_20 = Conv3D(256, (kernel, kernel, kernel), padding=\"same\")(unpool_3)\n","    conv_20 = BatchNormalization()(conv_20)\n","    conv_20 = Activation(\"relu\")(conv_20)\n","    conv_21 = Conv3D(256, (kernel, kernel, kernel), padding=\"same\")(conv_20)\n","    conv_21 = BatchNormalization()(conv_21)\n","    conv_21 = Activation(\"relu\")(conv_21)\n","    conv_22 = Conv3D(128, (kernel, kernel, kernel), padding=\"same\")(conv_21)\n","    conv_22 = BatchNormalization()(conv_22)\n","    conv_22 = Activation(\"relu\")(conv_22)\n","\n","    unpool_4 = UpSampling3D(pool_size)(conv_22)\n","\n","    conv_23 = Conv3D(128, (kernel, kernel, kernel), padding=\"same\")(unpool_4)\n","    conv_23 = BatchNormalization()(conv_23)\n","    conv_23 = Activation(\"relu\")(conv_23)\n","    conv_24 = Conv3D(64, (kernel, kernel, kernel), padding=\"same\")(conv_23)\n","    conv_24 = BatchNormalization()(conv_24)\n","    conv_24 = Activation(\"relu\")(conv_24)\n","\n","    unpool_5 = UpSampling3D(pool_size)(conv_24)\n","\n","    conv_25 = Conv3D(64, (kernel, kernel, kernel), padding=\"same\")(unpool_5)\n","    conv_25 = BatchNormalization()(conv_25)\n","    conv_25 = Activation(\"relu\")(conv_25)\n","\n","    conv_26 = Conv3D(n_labels, (1, 1, 1), padding=\"valid\")(conv_25)\n","    conv_26 = BatchNormalization()(conv_26)\n","    '''conv_26 = Reshape(\n","            (input_shape[0]*input_shape[1], n_labels),\n","            input_shape=(input_shape[0], input_shape[1], n_labels))(conv_26)'''\n","\n","    outputs = Activation(output_mode)(conv_26)\n","    print(\"Build decoder done..\")\n","    #pred = Reshape((168, 128, 128, 16))(outputs)\n","\n","    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n","    model.compile(optimizer= SGD(learning_rate=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n","                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n","    model.summary()\n","\n","    return model\n","\n","\n","\n","model = segnet(input_shape=(168, 128, 128, 16), n_labels=4)\n","\n","\n","model.summary()\n","print(model.input_shape)\n","print(model.output_shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKVhZj9r2lHQ","executionInfo":{"status":"ok","timestamp":1631900560428,"user_tz":-120,"elapsed":775,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"d9c36922-6116-4d8b-bb32-50b9b0cf7ebb"},"source":["from __future__ import absolute_import\n","from __future__ import print_function\n","import os\n","import numpy as np\n","from keras.utils import np_utils\n","from keras.applications import imagenet_utils\n","\n","\n","########################\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers.core import Activation, Reshape\n","from keras.layers import BatchNormalization\n","import tensorflow as tf\n","from torch.nn import MaxUnpool3d\n","from keras.layers import Conv3D, MaxPooling3D, concatenate, UpSampling3D\n","\n","\n","def SegNet(input_shape, classes):\n","    kernel=(3, 3, 3)\n","    pool_size=(2, 2, 2)\n","    output_mode=\"softmax\"\n","    \n","    img_input = Input(shape=input_shape)\n","    x = img_input\n","    # Encoder\n","    x = Conv3D(64, kernel, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    pool_1 = MaxPooling3D(pool_size=pool_size)(x)\n","    \n","    x = Conv3D(128, kernel, padding=\"same\")(pool_1)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    pool_2 = MaxPooling3D(pool_size=pool_size)(x)\n","    \n","    x = Conv3D(256, kernel, padding=\"same\")(pool_2)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    pool_3 = MaxPooling3D(pool_size=pool_size)(x)\n","    \n","    x = Conv3D(512,kernel, padding=\"same\")(pool_3)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    \n","    # Decoder\n","    x = Conv3D(512, kernel, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    \n","    x = UpSampling3D(size=pool_size)(x)\n","    x = Conv3D(256, kernel, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    \n","    x = UpSampling3D(size=pool_size)(x)\n","    x = Conv3D(128, kernel, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    \n","    x = UpSampling3D(size=pool_size)(x)\n","    x = Conv3D(64, kernel, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    \n","    x = Conv3D(classes, 1, 1, padding=\"valid\")(x)\n","    #x = Reshape((input_shape[0]*input_shape[1]*input_shape[2], classes))(x)\n","    x = Activation(\"softmax\")(x)\n","    model = Model(img_input, x)\n","\n","\n","    return model\n","\n","\n","\n","model = SegNet(input_shape=(128,128,128,3), classes=4)\n","\n","model.summary()\n","print(model.input_shape)\n","print(model.output_shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 128, 128, 128, 3) 0         \n","_________________________________________________________________\n","conv3d_52 (Conv3D)           (None, 128, 128, 128, 64) 5248      \n","_________________________________________________________________\n","batch_normalization_52 (Batc (None, 128, 128, 128, 64) 256       \n","_________________________________________________________________\n","activation_52 (Activation)   (None, 128, 128, 128, 64) 0         \n","_________________________________________________________________\n","max_pooling3d_10 (MaxPooling (None, 64, 64, 64, 64)    0         \n","_________________________________________________________________\n","conv3d_53 (Conv3D)           (None, 64, 64, 64, 128)   221312    \n","_________________________________________________________________\n","batch_normalization_53 (Batc (None, 64, 64, 64, 128)   512       \n","_________________________________________________________________\n","activation_53 (Activation)   (None, 64, 64, 64, 128)   0         \n","_________________________________________________________________\n","max_pooling3d_11 (MaxPooling (None, 32, 32, 32, 128)   0         \n","_________________________________________________________________\n","conv3d_54 (Conv3D)           (None, 32, 32, 32, 256)   884992    \n","_________________________________________________________________\n","batch_normalization_54 (Batc (None, 32, 32, 32, 256)   1024      \n","_________________________________________________________________\n","activation_54 (Activation)   (None, 32, 32, 32, 256)   0         \n","_________________________________________________________________\n","max_pooling3d_12 (MaxPooling (None, 16, 16, 16, 256)   0         \n","_________________________________________________________________\n","conv3d_55 (Conv3D)           (None, 16, 16, 16, 512)   3539456   \n","_________________________________________________________________\n","batch_normalization_55 (Batc (None, 16, 16, 16, 512)   2048      \n","_________________________________________________________________\n","activation_55 (Activation)   (None, 16, 16, 16, 512)   0         \n","_________________________________________________________________\n","conv3d_56 (Conv3D)           (None, 16, 16, 16, 512)   7078400   \n","_________________________________________________________________\n","batch_normalization_56 (Batc (None, 16, 16, 16, 512)   2048      \n","_________________________________________________________________\n","activation_56 (Activation)   (None, 16, 16, 16, 512)   0         \n","_________________________________________________________________\n","up_sampling3d_10 (UpSampling (None, 32, 32, 32, 512)   0         \n","_________________________________________________________________\n","conv3d_57 (Conv3D)           (None, 32, 32, 32, 256)   3539200   \n","_________________________________________________________________\n","batch_normalization_57 (Batc (None, 32, 32, 32, 256)   1024      \n","_________________________________________________________________\n","activation_57 (Activation)   (None, 32, 32, 32, 256)   0         \n","_________________________________________________________________\n","up_sampling3d_11 (UpSampling (None, 64, 64, 64, 256)   0         \n","_________________________________________________________________\n","conv3d_58 (Conv3D)           (None, 64, 64, 64, 128)   884864    \n","_________________________________________________________________\n","batch_normalization_58 (Batc (None, 64, 64, 64, 128)   512       \n","_________________________________________________________________\n","activation_58 (Activation)   (None, 64, 64, 64, 128)   0         \n","_________________________________________________________________\n","up_sampling3d_12 (UpSampling (None, 128, 128, 128, 128 0         \n","_________________________________________________________________\n","conv3d_59 (Conv3D)           (None, 128, 128, 128, 64) 221248    \n","_________________________________________________________________\n","batch_normalization_59 (Batc (None, 128, 128, 128, 64) 256       \n","_________________________________________________________________\n","activation_59 (Activation)   (None, 128, 128, 128, 64) 0         \n","_________________________________________________________________\n","conv3d_60 (Conv3D)           (None, 128, 128, 128, 4)  260       \n","_________________________________________________________________\n","activation_60 (Activation)   (None, 128, 128, 128, 4)  0         \n","=================================================================\n","Total params: 16,382,660\n","Trainable params: 16,378,820\n","Non-trainable params: 3,840\n","_________________________________________________________________\n","(None, 128, 128, 128, 3)\n","(None, 128, 128, 128, 4)\n"]}]},{"cell_type":"code","metadata":{"id":"D-W2Wpsh2Efg"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r49dAOGs2HOb","executionInfo":{"status":"ok","timestamp":1631900213115,"user_tz":-120,"elapsed":3618,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"89741f2e-a6a2-4537-8c27-6b8a9b9b71c2"},"source":["!pip install keras_applications"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n"]}]},{"cell_type":"code","metadata":{"id":"WtfgQPr32NV4","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1631900870532,"user_tz":-120,"elapsed":980,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"7089b87a-f5d1-4d27-c314-1c6da17a58e8"},"source":["wt0, wt1, wt2, wt3 = 0.25,0.25,0.25,0.25\n","import segmentation_models_3D as sm\n","dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3])) \n","focal_loss = sm.losses.CategoricalFocalLoss()\n","total_loss = dice_loss + (1 * focal_loss)\n","\n","#metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n","metrics = ['accuracy']\n","\n","LR = 0.0001\n","optim = tf.keras.optimizers.Adam(LR)\n","#######################################################################\n","#Fit the model \n","\n","steps_per_epoch = len(train_img_list)//batch_size\n","val_steps_per_epoch = len(val_img_list)//batch_size\n","\n","\n","model = SegNet((128,128,16, 1),4)\n","    # encoder\n","model.compile(optimizer= SGD(learning_rate=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n","                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n","#model.compile(optimizer = optim, loss=total_loss, metrics=metrics)\n","#print(model.summary())\n","\n","#print(model.input_shape)\n","#print(model.output_shape)\n","\n","#x_train, y_train = imageLoader(train_img_dir, train_img_list, \n","                                #train_mask_dir, train_mask_list, batch_size)\n","#x_val, y_val = imageLoader(val_img_dir, val_img_list, \n","                                #val_mask_dir, val_mask_list, batch_size)\n","\n","\n","history=model.fit(train_img_datagen,\n","          steps_per_epoch=steps_per_epoch,\n","          epochs=30,\n","          verbose=1,\n","          validation_data=val_img_datagen,\n","          )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-220fd46f5be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_img_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m           )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:789 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:246 sigmoid_cross_entropy_with_logits_v2\n        logits=logits, labels=labels, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:133 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((None, 128, 128, 16, 4) vs (None, None, None, None))\n"]}]},{"cell_type":"code","metadata":{"id":"5kOkwqJx5FfH"},"source":["x_train= imageLoader(train_img_dir, train_img_list, \n","                                train_mask_dir, train_mask_list, batch_size)\n","x_val= imageLoader(val_img_dir, val_img_list, \n","                                val_mask_dir, val_mask_list, batch_size)\n","\n","x_train, x_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7r65Ox-Q6WzY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631900145375,"user_tz":-120,"elapsed":445,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"42d12bd5-e507-449c-f30b-cc9b03ddd496"},"source":["import numpy as np\n","for i in range(20,25):\n","  my_mask =np.load('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/SplitData/val/t2_np/image_'+str(i)+'.npy')\n","  my_mask = my_mask[:,:,0:16].astype(np.float32)\n","  #my_mask = np.dtype(my_mask, np.uint8)\n","  np.save('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/SplitData/train/t2_np/image_'+str(i)+'.npy', my_mask)\n","  #maskarray = maskarray[:,:,0:16]\n","my_mask.shape, my_mask.dtype"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((128, 128, 16), dtype('float32'))"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"amO5sFUHtupd"},"source":["model = segnet(\n","        (168, 128, 128, 16),\n","        4)\n","hist = model.fit(x_train1, y_train1, epochs= 50, batch_size= 18, validation_data= (x_test, y_test), verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6D0u19-tFBQ"},"source":["import numpy as np\n","import nibabel as nib\n","import glob\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","from tifffile import imsave\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","\n","t2_list = sorted(glob.glob('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/DataSetBrats/Data/*/*t2.nii'))\n","mask_list = sorted(glob.glob('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/DataSetBrats/Data/*/*seg.nii'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vq2x9snXtYHH"},"source":["for img in range(25):\n","    print(\"Now preparing image and masks number: \", img)\n","   \n","\n","    temp_image_t2=nib.load(t2_list[img]).get_fdata()\n","    temp_image_t2=scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n","    temp_image_t2=temp_image_t2[56:184, 56:184, 13:141]\n","     \n","    temp_mask=nib.load(mask_list[img]).get_fdata()\n","    temp_mask=temp_mask.astype(np.uint8)\n","    temp_mask[temp_mask==4] = 3  #Reassign mask values 4 to 3\n","    temp_mask = temp_mask[56:184, 56:184, 13:141]\n","    #print(np.unique(temp_mask))\n","    \n","    \n","    #Crop to a size to be divisible by 64 so we can later extract 64x64x64 patches. \n","    #cropping x, y, and z\n","    #temp_mask= to_categorical(temp_mask, num_classes=4)\n","    #np.save('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/Origna_data_handling/t1/images/image_'+str(img)+'.npy', temp_image_t1)\n","    #np.save('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/Origna_data_handling/t1ce/images/image_'+str(img)+'.npy', temp_image_t1ce)\n","    np.save('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/t2_mask/t2_np/image_'+str(img)+'.npy', temp_image_t2)\n","    #np.save('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/Origna_data_handling/flair/images/image_'+str(img)+'.npy', temp_image_flair)\n","    np.save('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/example data/t2_mask/mask_np/mask_'+str(img)+'.npy', temp_mask) \n","   \n","     "],"execution_count":null,"outputs":[]}]}