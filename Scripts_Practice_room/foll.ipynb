{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"foll.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNwt7LqSlWKP4YmyUPpQJRP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"zG0SdncXxfi1","executionInfo":{"status":"ok","timestamp":1633879174855,"user_tz":-120,"elapsed":1254,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","import pickle\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nR0GZA-6xj3A","executionInfo":{"status":"ok","timestamp":1633879038286,"user_tz":-120,"elapsed":21876,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"0b2fb40b-3f3f-4f25-9a8c-7182342ed9ec"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\") # Don't change this."],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"GSoysPQBxlTj","executionInfo":{"status":"ok","timestamp":1633888070648,"user_tz":-120,"elapsed":36941,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["x_train = np.load('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/Prepared_MRI_data/Origna_data_handling/Stack_Arrays/train_images.npy')\n","x_test = np.load('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/Prepared_MRI_data/Origna_data_handling/Stack_Arrays/val_images.npy')\n","y_train = np.load('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/Prepared_MRI_data/Origna_data_handling/Stack_Arrays/train_masks.npy')\n","y_test = np.load('/content/drive/MyDrive/brain tumor segmentation/huzaifa data/Prepared_MRI_data/Origna_data_handling/Stack_Arrays/val_masks.npy')"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KV8j0GEM0L3u","executionInfo":{"status":"ok","timestamp":1633887863622,"user_tz":-120,"elapsed":422,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"dcdce434-4e4c-4567-fa0a-490cd10651dd"},"source":["x_train = x_train[:,:,:,60:63]\n","x_test = x_test[:,:,:,60:63]\n","x_train.shape\n","#x_test.shape"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(168, 128, 128, 3)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"veI_4rVixnsG","executionInfo":{"status":"ok","timestamp":1633887875361,"user_tz":-120,"elapsed":977,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.20, random_state = 101)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"QqieihjgTlYh","executionInfo":{"status":"ok","timestamp":1633888124479,"user_tz":-120,"elapsed":676,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["x_train = x_train[:,:,:,60:63]\n","x_test = x_test[:,:,:,60:63]\n","y_train=y_train[:,:,:,60:63]\n","y_test=y_test[:,:,:,60:63]\n","x_val=x_val[:,:,:,60:63]\n","y_val=y_val[:,:,:,60:63]\n"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kRH9J9bvUmUV","executionInfo":{"status":"ok","timestamp":1633888139310,"user_tz":-120,"elapsed":368,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"e259bc66-44c0-4e0f-83ff-5e7563986f9e"},"source":["x_train.shape"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(168, 128, 128, 3)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"_9nwFN_xxylA","executionInfo":{"status":"ok","timestamp":1633892198865,"user_tz":-120,"elapsed":393,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["from keras import backend as K\n","from keras.layers import Layer\n","\n","\n","class MaxPoolingWithArgmax2D(Layer):\n","    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=\"same\", **kwargs):\n","        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n","        self.padding = padding\n","        self.pool_size = pool_size\n","        self.strides = strides\n","\n","    def call(self, inputs, **kwargs):\n","        padding = self.padding\n","        pool_size = self.pool_size\n","        strides = self.strides\n","        if K.backend() == \"tensorflow\":\n","            ksize = [1, pool_size[0], pool_size[1], 1]\n","            padding = padding.upper()\n","            strides = [1, strides[0], strides[1], 1]\n","            output, argmax = K.tf.nn.max_pool_with_argmax(\n","                inputs, ksize=ksize, strides=strides, padding=padding\n","            )\n","        else:\n","            errmsg = \"{} backend is not supported for layer {}\".format(\n","                K.backend(), type(self).__name__\n","            )\n","            raise NotImplementedError(errmsg)\n","        argmax = K.cast(argmax, K.floatx())\n","        return [output, argmax]\n","\n","    def compute_output_shape(self, input_shape):\n","        ratio = (1, 2, 2, 1)\n","        output_shape = [\n","            dim // ratio[idx] if dim is not None else None\n","            for idx, dim in enumerate(input_shape)\n","        ]\n","        output_shape = tuple(output_shape)\n","        return [output_shape, output_shape]\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return 2 * [None]\n","\n","\n","class MaxUnpooling2D(Layer):\n","    def __init__(self, size=(2, 2), **kwargs):\n","        super(MaxUnpooling2D, self).__init__(**kwargs)\n","        self.size = size\n","\n","    def call(self, inputs, output_shape=None):\n","        updates, mask = inputs[0], inputs[1]\n","        with tf.compat.v1.variable_scope(self.name):\n","            mask = K.cast(mask, \"int32\")\n","            input_shape = K.tf.shape(updates, out_type=\"int32\")\n","            #  calculation new shape\n","            if output_shape is None:\n","                output_shape = (\n","                    input_shape[0],\n","                    input_shape[1] * self.size[0],\n","                    input_shape[2] * self.size[1],\n","                    input_shape[3],\n","                )\n","            self.output_shape1 = output_shape\n","\n","            # calculation indices for batch, height, width and feature maps\n","            one_like_mask = K.ones_like(mask, dtype=\"int32\")\n","            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n","            batch_range = K.reshape(\n","                K.tf.range(output_shape[0], dtype=\"int32\"), shape=batch_shape\n","            )\n","            b = one_like_mask * batch_range\n","            y = mask // (output_shape[2] * output_shape[3])\n","            x = (mask // output_shape[3]) % output_shape[2]\n","            feature_range = K.tf.range(output_shape[3], dtype=\"int32\")\n","            f = one_like_mask * feature_range\n","\n","            # transpose indices & reshape update values to one dimension\n","            updates_size = K.tf.size(updates)\n","            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n","            values = K.reshape(updates, [updates_size])\n","            ret = K.tf.scatter_nd(indices, values, output_shape)\n","            return ret\n","\n","    def compute_output_shape(self, input_shape):\n","        mask_shape = input_shape[1]\n","        return (\n","            mask_shape[0],\n","            mask_shape[1] * self.size[0],\n","            mask_shape[2] * self.size[1],\n","            mask_shape[3],\n","        )"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PgNMd_Ix54B","executionInfo":{"status":"ok","timestamp":1633897939458,"user_tz":-120,"elapsed":469,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Activation, Reshape, Dense\n","from tensorflow.keras.layers import Convolution2D\n","from tensorflow.keras.layers import BatchNormalization\n","import numpy \n","\n","#from layers import MaxPoolingWithArgmax2D, MaxUnpooling2D\n","\n","def segnet(\n","        input_shape,\n","        n_labels,\n","        kernel=3,\n","        pool_size=(2, 2),\n","        output_mode=\"softmax\"):\n","    # encoder\n","    inputs = Input(shape=input_shape)\n","\n","    \n","\n","    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal', name=\"block1_conv1\")(inputs)\n","    conv_1 = BatchNormalization()(conv_1)\n","    conv_1 = Activation(\"relu\")(conv_1)\n","\n","    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal', name=\"block1_conv2\")(conv_1)\n","    conv_2 = BatchNormalization()(conv_2)\n","    conv_2 = Activation(\"relu\")(conv_2)\n","    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size, name=\"block1_pool\")(conv_2)\n","\n","    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\" , kernel_initializer='he_normal', name=\"block2_conv1\")(pool_1)\n","    conv_3 = BatchNormalization()(conv_3)\n","    conv_3 = Activation(\"relu\")(conv_3)\n","    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal',  name=\"block2_conv2\")(conv_3)\n","    conv_4 = BatchNormalization()(conv_4)\n","    conv_4 = Activation(\"relu\")(conv_4)\n","\n","    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size, name=\"block2_pool\")(conv_4)\n","\n","    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\" , kernel_initializer='he_normal', name=\"block3_conv1\")(pool_2)\n","    conv_5 = BatchNormalization()(conv_5)\n","    conv_5 = Activation(\"relu\")(conv_5)\n","    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\" , kernel_initializer='he_normal', name=\"block3_conv2\")(conv_5)\n","    conv_6 = BatchNormalization()(conv_6)\n","    conv_6 = Activation(\"relu\")(conv_6)\n","    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\" , kernel_initializer='he_normal', name=\"block3_conv3\")(conv_6)\n","    conv_7 = BatchNormalization()(conv_7)\n","    conv_7 = Activation(\"relu\")(conv_7)\n","\n","    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size, name=\"block3_pool\")(conv_7)\n","\n","    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal', name=\"block4_conv1\")(pool_3)\n","    conv_8 = BatchNormalization()(conv_8)\n","    conv_8 = Activation(\"relu\")(conv_8)\n","    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\" , kernel_initializer='he_normal', name=\"block4_conv2\")(conv_8)\n","    conv_9 = BatchNormalization()(conv_9)\n","    conv_9 = Activation(\"relu\")(conv_9)\n","    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\" , kernel_initializer='he_normal', name=\"block4_conv3\")(conv_9)\n","    conv_10 = BatchNormalization()(conv_10)\n","    conv_10 = Activation(\"relu\")(conv_10)\n","\n","    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size, name=\"block4_pool\")(conv_10)\n","\n","    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal', name=\"block5_conv1\")(pool_4)\n","    conv_11 = BatchNormalization()(conv_11)\n","    conv_11 = Activation(\"relu\")(conv_11)\n","    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\" , kernel_initializer='he_normal',  name=\"block5_conv2\")(conv_11)\n","    conv_12 = BatchNormalization()(conv_12)\n","    conv_12 = Activation(\"relu\")(conv_12)\n","    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\" , kernel_initializer='he_normal',  name=\"block5_conv3\")(conv_12)\n","    conv_13 = BatchNormalization()(conv_13)\n","    conv_13 = Activation(\"relu\")(conv_13)\n","\n","\n","    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size, name=\"block5_pool\")(conv_13)\n","\n","   \n","    # decoder\n","    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n","\n","\n","    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(unpool_1)\n","    print(\"UNPOOLKING RANNNN\")\n","    conv_14 = BatchNormalization()(conv_14)\n","    conv_14 = Activation(\"relu\")(conv_14)\n","    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(conv_14)\n","    conv_15 = BatchNormalization()(conv_15)\n","    conv_15 = Activation(\"relu\")(conv_15)\n","    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(conv_15)\n","    conv_16 = BatchNormalization()(conv_16)\n","    conv_16 = Activation(\"relu\")(conv_16)\n","\n","    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n","\n","    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(unpool_2)\n","    conv_17 = BatchNormalization()(conv_17)\n","    conv_17 = Activation(\"relu\")(conv_17)\n","    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(conv_17)\n","    conv_18 = BatchNormalization()(conv_18)\n","    conv_18 = Activation(\"relu\")(conv_18)\n","    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(conv_18)\n","    conv_19 = BatchNormalization()(conv_19)\n","    conv_19 = Activation(\"relu\")(conv_19)\n","\n","    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n","\n","    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(unpool_3)\n","    conv_20 = BatchNormalization()(conv_20)\n","    conv_20 = Activation(\"relu\")(conv_20)\n","    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(conv_20)\n","    conv_21 = BatchNormalization()(conv_21)\n","    conv_21 = Activation(\"relu\")(conv_21)\n","    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(conv_21)\n","    conv_22 = BatchNormalization()(conv_22)\n","    conv_22 = Activation(\"relu\")(conv_22)\n","\n","    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n","\n","    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(unpool_4)\n","    conv_23 = BatchNormalization()(conv_23)\n","    conv_23 = Activation(\"relu\")(conv_23)\n","    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(conv_23)\n","    conv_24 = BatchNormalization()(conv_24)\n","    conv_24 = Activation(\"relu\")(conv_24)\n","\n","    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n","\n","    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\", kernel_initializer='he_normal')(unpool_5)\n","    conv_25 = BatchNormalization()(conv_25)\n","    conv_25 = Activation(\"relu\")(conv_25)\n","\n","    conv_26 = Convolution2D(n_labels, (1, 1), padding=\"same\", kernel_initializer='he_normal')(conv_25)\n","    conv_26 = BatchNormalization()(conv_26)\n","\n","    #conv_26 = Dense(4)(conv_26)\n","    outputs = Activation(output_mode)(conv_26)\n","    print(\"Build decoder done..\")\n","\n","    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n","\n","    return model"],"execution_count":118,"outputs":[]},{"cell_type":"code","metadata":{"id":"V7SPVLCqyEVX","executionInfo":{"status":"ok","timestamp":1633897935156,"user_tz":-120,"elapsed":1140,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["input_shape = (256,1600,1)\n","from keras import backend as K\n","from keras.layers import Layer\n","import tensorflow as tf\n","\n","\n","class MaxPoolingWithArgmax2D(Layer):\n","\n","    def __init__(\n","            self,\n","            pool_size=(2, 2),\n","            strides=(2, 2),\n","            padding='same',\n","            **kwargs):\n","        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n","        self.padding = padding\n","        self.pool_size = pool_size\n","        self.strides = strides\n","\n","    def call(self, inputs, **kwargs):\n","        print(\"max pooling with argmax\")\n","        padding = self.padding\n","        pool_size = self.pool_size\n","        strides = self.strides\n","        if K.backend() == 'tensorflow':\n","            ksize = [1, pool_size[0], pool_size[1], 1]\n","            padding = padding.upper()\n","            strides = [1, strides[0], strides[1], 1]\n","            output, argmax = tf.nn.max_pool_with_argmax(\n","                    inputs,\n","                    ksize=ksize,\n","                    strides=strides,\n","                    padding=padding)\n","        else:\n","            errmsg = '{} backend is not supported for layer {}'.format(\n","                    K.backend(), type(self).__name__)\n","            raise NotImplementedError(errmsg)\n","        argmax = K.cast(argmax, K.floatx())\n","        return [output, argmax]\n","\n","    def compute_output_shape(self, input_shape):\n","        print(\"i guess its subsampling\")\n","        ratio = (1, 2, 2, 1)\n","        output_shape = [\n","                dim//ratio[idx]\n","                if dim is not None else None\n","                for idx, dim in enumerate(input_shape)]\n","        output_shape = tuple(output_shape)\n","        return [output_shape, output_shape]\n","\n","\n","    def compute_mask(self, inputs, mask=None):\n","        print(\"no idea what this is: but computing mask\")\n","        return 2 * [None]\n","\n","\n","\n"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"gafW8rf3U8QY","executionInfo":{"status":"error","timestamp":1633897944096,"user_tz":-120,"elapsed":829,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"93aa781c-a3da-4999-e388-da949520b30e"},"source":["model= segnet(input_shape=input_shape, n_labels=4)  #, single_model"],"execution_count":119,"outputs":[{"output_type":"stream","name":"stdout","text":["max pooling with argmax\n","no idea what this is: but computing mask\n","max pooling with argmax\n","no idea what this is: but computing mask\n","max pooling with argmax\n","no idea what this is: but computing mask\n","max pooling with argmax\n","no idea what this is: but computing mask\n","max pooling with argmax\n","no idea what this is: but computing mask\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-119-2d2dc1686c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msegnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#, single_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-118-24e50e7e72d8>\u001b[0m in \u001b[0;36msegnet\u001b[0;34m(input_shape, n_labels, kernel, pool_size, output_mode)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mconv_14\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpool_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNPOOLKING RANNNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconv_14\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0minput_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_input_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_channel\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m_get_input_channel\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mchannel_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_channel_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m       raise ValueError('The channel dimension of the inputs '\n\u001b[0m\u001b[1;32m    367\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The channel dimension of the inputs should be defined. Found `None`."]}]},{"cell_type":"code","metadata":{"id":"Kw6HYVZ8QMFP","executionInfo":{"status":"ok","timestamp":1633903803385,"user_tz":-120,"elapsed":418,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["class MaxPoolingWithArgmax2D(Layer):\n","\n","  def __init__(\n","          self,\n","          pool_size=(2, 2),\n","          strides=2,\n","          padding='same',\n","          **kwargs):\n","      super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n","      self.padding = padding\n","      self.pool_size = pool_size\n","      self.strides = strides\n","\n","  def call(self, inputs, **kwargs):\n","      padding = self.padding\n","      pool_size = self.pool_size\n","      strides = self.strides\n","      output, argmax = tf.nn.max_pool_with_argmax(\n","          inputs,\n","          ksize=pool_size,\n","          strides=strides,\n","          padding=padding.upper(),\n","          output_dtype=tf.int64)\n","      return output, argmax"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"D75RODbbP5pP","executionInfo":{"status":"ok","timestamp":1633907375168,"user_tz":-120,"elapsed":334,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["class MaxUnpooling2D(Layer):\n","  def __init__(self, size=(2, 2), **kwargs):\n","      super(MaxUnpooling2D, self).__init__(**kwargs)\n","      self.size = size\n","\n","  def call(self, inputs, output_shape=None):\n","      updates, mask = inputs[0], inputs[1]\n","      with tf.compat.v1.variable_scope(self.name):\n","          mask = K.cast(mask, 'int32')\n","          input_shape = tf.shape(updates, out_type='int32')\n","          #print(updates.shape)\n","          #print(mask.shape)\n","          if output_shape is None:\n","              output_shape = (\n","                  input_shape[0],\n","                  input_shape[1] * self.size[0],\n","                  input_shape[2] * self.size[1],\n","                  input_shape[3])\n","\n","          ret = tf.scatter_nd(K.expand_dims(K.flatten(mask)),\n","                                K.flatten(updates),\n","                                [K.prod(output_shape)])\n","\n","          input_shape = updates.shape\n","          out_shape = [-1,\n","                       input_shape[1] * self.size[0],\n","                       input_shape[2] * self.size[1],\n","                       input_shape[3]]\n","      return K.reshape(ret, out_shape)\n","\n","def get_config(self):\n","    config = super().get_config().copy()\n","    config.update({\n","        'size': self.size\n","    })\n","    return config\n","\n","def compute_output_shape(self, input_shape):\n","    mask_shape = input_shape[1]\n","    return (\n","            mask_shape[0],\n","            mask_shape[1]*self.size[0],\n","            mask_shape[2]*self.size[1],\n","            mask_shape[3]\n","            )"],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOJBES12PxNM","executionInfo":{"status":"ok","timestamp":1633907393120,"user_tz":-120,"elapsed":359,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}}},"source":["import tensorflow as tf\n","import tensorflow.keras as keras\n","import tensorflow.keras.layers as layers\n","from tensorflow.keras.layers import Layer\n","\n","\n","class SegNet:\n","    def __init__(self, data_shape, classes = 4, batch_size = None):\n","        self.MODEL_NAME = 'SegNet'\n","        self.MODEL_VERSION = '0.2'\n","\n","        self.classes = classes\n","        self.batch_size = batch_size\n","\n","        self.build_model(data_shape)\n","\n","    def build_model(self, data_shape):\n","        input_shape = (data_shape, data_shape, 3)\n","\n","        inputs = keras.Input(shape=input_shape, batch_size=self.batch_size, name='Input')\n","\n","        # Build sequential model\n","\n","        # Encoding\n","        encoders = 5\n","        feature_maps = [64, 128, 256, 512, 512]\n","        n_convolutions = [2, 2, 3, 3, 3]\n","        eb_input = inputs\n","        eb_argmax_indices = []\n","        for encoder_index in range(encoders):\n","            encoder_block, argmax_indices = self.encoder_block(\n","                eb_input, encoder_index, feature_maps[encoder_index], n_convolutions[encoder_index])\n","            eb_argmax_indices.append(argmax_indices)\n","            eb_input = encoder_block\n","\n","        # Decoding\n","        decoders = encoders\n","        db_input = encoder_block\n","        eb_argmax_indices.reverse()\n","        feature_maps.reverse()\n","        n_convolutions.reverse()\n","        d_feature_maps = [512, 512, 256, 128, 64]\n","        d_n_convolutions = n_convolutions\n","        for decoder_index in range(decoders):\n","            decoder_block = self.decoder_block(\n","                db_input, eb_argmax_indices[decoder_index], decoder_index, d_feature_maps[decoder_index], d_n_convolutions[decoder_index])\n","            db_input = decoder_block\n","\n","        output = layers.Softmax()(decoder_block)\n","\n","        self.model = keras.Model(inputs=inputs, outputs=output, name=\"SegNet\")\n","\n","    def encoder_block(self, x, encoder_index, feature_maps, n_convolutions):\n","        bank_input = x\n","        for conv_index in range(n_convolutions):\n","            bank = self.eb_layers_bank(\n","                bank_input, conv_index, feature_maps, encoder_index)\n","            bank_input = bank\n","\n","        max_pool, indices = MaxPoolingWithArgmax2D(pool_size=(\n","            2, 2), strides=2, padding='same', name='EB_{}_MPOOL'.format(encoder_index + 1))(bank)\n","\n","        return max_pool, indices\n","\n","    def eb_layers_bank(self, x, bank_index, feature_maps, encoder_index):\n","\n","        bank_input = x\n","\n","        conv_l = layers.Conv2D(feature_maps, (3, 3), padding='same', name='EB_{}_BANK_{}_CONV'.format(\n","            encoder_index + 1, bank_index + 1))(bank_input)\n","        batch_norm = layers.BatchNormalization(\n","            name='EB_{}_BANK_{}_BN'.format(encoder_index + 1, bank_index + 1))(conv_l)\n","        relu = layers.ReLU(name='EB_{}_BANK_{}_RL'.format(\n","            encoder_index + 1, bank_index + 1))(batch_norm)\n","\n","        return relu\n","\n","    def decoder_block(self, x, max_pooling_idices, decoder_index, feature_maps, n_convolutions):\n","        #bank_input = self.unpool_with_argmax(x, max_pooling_idices)\n","        bank_input = MaxUnpooling2D(name='DB_{}_UPSAMP'.format(decoder_index + 1))([x, max_pooling_idices])\n","        #bank_input = layers.UpSampling2D()(x)\n","        for conv_index in range(n_convolutions):\n","            if conv_index == n_convolutions - 1:\n","                last_l_banck = True\n","            else:\n","                last_l_banck = False\n","            bank = self.db_layers_bank(\n","                bank_input, conv_index, feature_maps, decoder_index, last_l_banck)\n","            bank_input = bank\n","\n","        return bank\n","\n","    def db_layers_bank(self, x, bank_index, feature_maps, decoder_index, last_l_bank):\n","        bank_input = x\n","\n","        if (last_l_bank) & (decoder_index == 4):\n","            conv_l = layers.Conv2D(self.classes, (1, 1), padding='same', name='DB_{}_BANK_{}_CONV'.format(\n","                decoder_index + 1, bank_index + 1))(bank_input)\n","            #batch_norm = layers.BatchNormalization(\n","            #    name='DB_{}_BANK_{}_BN'.format(decoder_index + 1, bank_index + 1))(conv_l)\n","            return conv_l\n","        else:\n","\n","            if (last_l_bank) & (decoder_index > 0):\n","                conv_l = layers.Conv2D(int(feature_maps / 2), (3, 3), padding='same', name='DB_{}_BANK_{}_CONV'.format(\n","                    decoder_index + 1, bank_index + 1))(bank_input)\n","            else:\n","                conv_l = layers.Conv2D(feature_maps, (3, 3), padding='same', name='DB_{}_BANK_{}_CONV'.format(\n","                    decoder_index + 1, bank_index + 1))(bank_input)\n","            batch_norm = layers.BatchNormalization(\n","                name='DB_{}_BANK_{}_BN'.format(decoder_index + 1, bank_index + 1))(conv_l)\n","            relu = layers.ReLU(name='DB_{}_BANK_{}_RL'.format(\n","                decoder_index + 1, bank_index + 1))(batch_norm)\n","\n","            return relu\n","\n","    def get_model(self):\n","        return self.model"],"execution_count":132,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"f9es_ONBQa1a","executionInfo":{"status":"error","timestamp":1633907397782,"user_tz":-120,"elapsed":350,"user":{"displayName":"Huzaifa Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLYtmrg9ffTuIoG7yviU5wA27X_NroIWVZbOUj=s64","userId":"08238025780309927389"}},"outputId":"dd5736f0-ccae-48cc-b0d5-1042bf55c33c"},"source":["data_shape=(128,128,3)\n","model=SegNet(data_shape)"],"execution_count":133,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-133-f9a43b0b12b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSegNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-132-13ec87851ae8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_shape, classes, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-132-13ec87851ae8>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, data_shape)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Build sequential model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m     input_layer_config.update(\n\u001b[1;32m    382\u001b[0m         {'batch_size': batch_size, 'input_shape': shape})\n\u001b[0;32m--> 383\u001b[0;31m   \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_layer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m   \u001b[0;31m# Return tensor including `_keras_history`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             ragged=ragged)\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name, ragged)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       spec = tf.TensorSpec(\n\u001b[0;32m-> 1316\u001b[0;31m           shape=shape, dtype=dtype, name=name)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_tensor_from_type_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_spec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, dtype, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mnot\u001b[0m \u001b[0mconvertible\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \"\"\"\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \"\"\"\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    207\u001b[0m             TypeError(\"Dimension value must be integer or None or have \"\n\u001b[1;32m    208\u001b[0m                       \u001b[0;34m\"an __index__ method, got value '{0!r}' with type '{1!r}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                       .format(value, type(value))), None)\n\u001b[0m\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dimension %d must be >= 0\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '(128, 128, 3)' with type '<class 'tuple'>'"]}]},{"cell_type":"code","metadata":{"id":"mZghmMoOQd8W"},"source":[""],"execution_count":null,"outputs":[]}]}